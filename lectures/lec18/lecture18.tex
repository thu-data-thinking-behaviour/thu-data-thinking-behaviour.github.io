\documentclass[xetex,mathserif,serif,aspectratio=169]{beamer}

\input{../import.tex}
\usepackage[]{algorithm2e}
\usepackage{../kbordermatrix}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\vfill

{\fontsize{0.7cm}{0cm}\selectfont Lecture 18 \\\vspace{0.2cm}
Transfer Learning and Computer Vision I}\\\vspace{0.5cm}
04 April 2016

\vspace{2cm}

\begin{minipage}{0.6\textwidth}
Taylor B. Arnold \\
Yale Statistics \\
STAT 365/665
\end{minipage}
\hfill
\begin{minipage}{0.3\textwidth}\raggedleft
\includegraphics[scale=0.3]{../yale-logo.png}
\end{minipage}%

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

Notes:
\begin{itemize}
\item Problem set 6 is online and due \textbf{this} Friday, April 8th
\item Problem set 7 is online and due \textbf{next} Friday, April 15th
\item No class next week
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{}

\begin{flushright}
{\color{yaleblue}\sc\fontsize{1cm}{0.5cm}\selectfont Autoencoders and Transfer Learning}
\end{flushright}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{An Autoencoder}}

An autoencoder is a learning algorithm that attempts to
learn a compressed representation of its output. It is
conceptually an unsupervised task, but one that neural
networks are quite good at.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{Neural network Autoencoder}}

To build a neural network auto-encoder, we simply build a neural
network where the input is equal to the output. This is only meaningful
when there exists a hidden layer with fewer nodes than the input
layer (otherwise we can perfectly reconstruct the image):

\begin{center}
\includegraphics[height=0.5\textheight]{img/autoencoder_network1.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{The botteneck layer}}

Notice that by storing the values in the hidden layer with
the fewest nodes, we get a compression of the input into a
lower dimensional space (other hidden layers also do this, but
may do a smaller amount of compression).

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{Dimensionality reduction}}

We can reason that for many tasks, if this lower dimensional representation
does a good job of reconstructing the image, there is enough information
contained in that layer to also do learning tasks. If the degree of compression
is high, this can aid in learning because the input dimensionality has been
reduced.

\pause This is exactly the same as computing principal components and then using
the first few components to do regression on.

\pause It turns out, very helpfully, that the hidden layers of non-autoencoding
networks perform a supervised dimensionality reduction. We can often think of
the inner layers in the same way as the bottleneck layers for an autoencoder.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{Autoencoder demo}}

A live demo of an autoencoder on the MNIST-10 dataset:
\begin{quote}
\url{http://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html}
\end{quote}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \footnotesize

\yblue{\textbf{Transfer learning}}

Remember when we were predicting crimes on the City of Chicago dataset; many
of you were quite concerned about why the following worked so well:
\begin{enumerate}
\item Train a model on the output $Z$, using the covariate matrix $X$
\item Use the predicted values, along with $X$, to learn a new output $Y$
\end{enumerate}
\pause We can do this with neural networks in a more natural way by:
\begin{enumerate}
\item Train a neural network on an output $Z$, using the inputs $X$
\item Remove the learned output layer from this network, and attach another
output layer to capture a new output $Y$
\item Train this new model, either using the weights from the first step as
a starting point (pre-training) or freezing them (transfer learning)
\end{enumerate}
Does this process make more intuitive sense now that we can see the first
step as supervised dimensionality reduction?

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \footnotesize

\yblue{\textbf{Why is this all important?}}

In order to get state-of-the-art results using neural networks, we
need to train very large and deep models. This requires a lot of
data and computing power, both of which most users do not have.
To circumvent this, some combination of pre-training or transfer
learning is used instead.

This is largely why understanding the recent history of computer
vision models is so important; most computer visions tasks will
require one to use and modify these models in some form.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{Autoencoding, Transfer Learning, and Pre-training}}

Good references for these topics are given by
\begin{quote}
Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller, X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., and Bergstra, J. (2011). Unsupervised and transfer learning challenge: a deep learning approach.
\end{quote}
And,
\begin{quote}
Long, Jonathan L., Ning Zhang, and Trevor Darrell. "Do Convnets Learn Correspondence?." Advances in Neural Information Processing Systems. 2014.
\end{quote}

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{}

\begin{flushright}
{\color{yaleblue}\sc\fontsize{1cm}{1cm}\selectfont Computer Vision I}
\end{flushright}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{CNN Review}}

A 5x5 kernel with a stride of $1$:

\begin{center}
\includegraphics[height=0.66\textheight]{img/tikz45.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{CNN Review}}

Max pooling with 2x2 kernel and stride of $2$:

\begin{center}
\includegraphics[height=0.66\textheight]{img/tikz47.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{CNN Review}}

A complete CNN model:

\begin{center}
\includegraphics[height=0.5\textheight]{img/tikz49.png}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \footnotesize

\yblue{\textbf{Convolutional Models in Computer Vision}}

There is a long history of specific advances and uses of convolutional
neural networks. Today, I'll focus on the following set of models: \vspace*{-0.5cm}
\begin{itemize}
\item LeNet-5 (1998)
\item AlexNet (2012)
\item OverFeat (2013)
\item VGG-16, VGG-19 (2014)
\item GoogLeNet (2014)
\item PReLUnet (2015)
\item ResNet-50, ResNet-101, ResNet-152 (2015)
\item SqueezeNet (2016)
\item Stochastic Depth (2016)
\item ResNet-200, ResNet-1001 (2016)
\end{itemize} \vspace*{-0.5cm}
When you hear about these models people may be referring to: the architecture,
the architecture and weights, or just to the general approach.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{LeNet-5 (1998)}}

LeNet was one of first models to really show the power of convolutional
neural networks. It was first applied to the MNIST-10 dataset, created
by a similar group of individuals:
\begin{quote}
LeCun, Y., Bottou, L., Bengio, Y. and Haffner, P., 1998. Gradient-based
learning applied to document recognition. Proceedings of the IEEE, 86(11),
pp.2278-2324.
\end{quote}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/lenet5.jpg}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.7\textwidth]{img/leNetCompare.jpg}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\textbf{\magenta{Python demo I: LeNet-5 for MNIST10}}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\textbf{\magenta{Python demo II:  LeNet-5 with ``Distortions" (i.e., Data augmentation)}}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/ilsvrc.jpg}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\yblue{\textbf{ImageNet Overview (through 2014)}}

An excellent summery paper of the ILSVCR challeneg, that
describes in more detail than I will here, is given by:
\begin{quote}
Olga Russakovsky, et al. "ImageNet Large Scale Visual Recognition Challenge".
arXiv preprint arXiv:1409.0575v3 (2015).
\end{quote}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/ilsvrcSize.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/ilsvrcCategories.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.85\textwidth]{img/ilsvrcTasks.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/ilsvrcDifficult.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.7\textwidth]{img/ilsvrcDifficultClasses.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.7\textwidth]{img/ilsvrcDifficultLocalization.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=\textwidth]{img/ilsvrcCommonErrors.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.63\textwidth]{img/ilsvrcClassRates.jpg}
\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{} \oldB \small

\begin{center}
\includegraphics[width=0.7\textwidth]{img/ilsvrcLocalRates.jpg}
\end{center}

\end{frame}


\end{document}







