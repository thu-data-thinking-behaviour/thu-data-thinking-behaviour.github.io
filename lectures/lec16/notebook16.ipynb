{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras with MNIST\n",
    "Import various modules that we need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/taylor/anaconda3/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset, flatten the images, convert the class labels, and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 28**2).astype('float32') / 255\n",
    "X_test = X_test.reshape(10000, 28**2).astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Basic example \n",
    "Build and compile a basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(28 * 28,)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(10))\n",
    "          \n",
    "sgd = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss='mse', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model over 25 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 10s - loss: 0.0497 - acc: 0.7867 - val_loss: 0.0419 - val_acc: 0.8592\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 11s - loss: 0.0427 - acc: 0.8439 - val_loss: 0.0388 - val_acc: 0.8773\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 11s - loss: 0.0415 - acc: 0.8475 - val_loss: 0.0392 - val_acc: 0.8683\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 11s - loss: 0.0408 - acc: 0.8499 - val_loss: 0.0370 - val_acc: 0.8857\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s - loss: 0.0402 - acc: 0.8514 - val_loss: 0.0368 - val_acc: 0.8848\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 13s - loss: 0.0395 - acc: 0.8549 - val_loss: 0.0378 - val_acc: 0.8710\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 14s - loss: 0.0388 - acc: 0.8582 - val_loss: 0.0356 - val_acc: 0.8848\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 14s - loss: 0.0379 - acc: 0.8607 - val_loss: 0.0341 - val_acc: 0.8918\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 13s - loss: 0.0368 - acc: 0.8656 - val_loss: 0.0329 - val_acc: 0.8930\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 14s - loss: 0.0355 - acc: 0.8705 - val_loss: 0.0332 - val_acc: 0.8932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1041ffbe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n",
      "Test classification rate 0.87960\n"
     ]
    }
   ],
   "source": [
    "print(\"Test classification rate %0.05f\" % model.evaluate(X_test, Y_test, show_accuracy=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict classes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1116</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>848</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>923</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>690</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>880</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>92</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1    2    3    4    5    6    7    8    9\n",
       "row_0                                                   \n",
       "0      947     0   18    3    0   17   15    5   16   18\n",
       "1        0  1116   32    6   25   16    7   45   39   14\n",
       "2        1     2  848   16    4    5    6   16   10    1\n",
       "3        2     2   30  923    1   77    0    8   45   17\n",
       "4        0     0    8    0  828    6    7   10    7   27\n",
       "5        7     1    0   10    3  690   21    1   35    2\n",
       "6       16     5   36    9   22   22  901    3   18    2\n",
       "7        1     0   16   13    1   11    0  880    5   23\n",
       "8        4     9   36   16    6   25    1    0  760    2\n",
       "9        2     0    8   14   92   23    0   60   39  903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_classes(X_test)\n",
    "pd.crosstab(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Deeper model with dropout and cross entropy\n",
    "\n",
    "Let's now build a deeper model, with four hidden dense layers and dropout layers. I'll use rectified linear units as they tend to perform better on deep models. I also initilize the nodes using \"glorot_normal\", which uses Gaussian noise scaled by the sum of the inputs plus outputs from the node. Notice that we do not need to give an input shape to any layers other than the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 27s - loss: 0.5660 - acc: 0.8167 - val_loss: 0.1335 - val_acc: 0.9612\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 27s - loss: 0.2677 - acc: 0.9242 - val_loss: 0.0948 - val_acc: 0.9727\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 28s - loss: 0.2115 - acc: 0.9408 - val_loss: 0.0894 - val_acc: 0.9747\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.1840 - acc: 0.9478 - val_loss: 0.0771 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.1617 - acc: 0.9538 - val_loss: 0.0739 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 29s - loss: 0.1419 - acc: 0.9602 - val_loss: 0.0729 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 31s - loss: 0.1373 - acc: 0.9611 - val_loss: 0.0766 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 33s - loss: 0.1268 - acc: 0.9637 - val_loss: 0.0632 - val_acc: 0.9818\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 32s - loss: 0.1148 - acc: 0.9674 - val_loss: 0.0693 - val_acc: 0.9808\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 30s - loss: 0.1084 - acc: 0.9695 - val_loss: 0.0706 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123192cc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Test classification rate %0.05f\" % model.evaluate(X_test, Y_test, show_accuracy=True)[1])\n",
    "fy_hat = model.predict_classes(X_test)\n",
    "pd.crosstab(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_wrong = [im for im in zip(X_test,y_hat,y_test) if im[1] != im[2]]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for ind, val in enumerate(test_wrong[:100]):\n",
    "    plt.subplot(10, 10, ind + 1)\n",
    "    im = 1 - val[0].reshape((28,28))\n",
    "    axis(\"off\")\n",
    "    plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Small model: Visualizing weights\n",
    "Now, I want to make a model that has only a small number of hidden nodes in each layer. We may then have a chance of actually visualizing the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification rate on the validation set is not nearly as predictive, but it is still not too bad overall. A model object contains a list of its layers. The weights are easy to pull out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.layers) # list of the layers\n",
    "print(model.layers[0].get_weights()[0].shape) # the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first set of weights will be given as weights the same size as the input space. Notice how "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = model.layers[0].get_weights()[0]\n",
    "\n",
    "for ind, val in enumerate(W1.T):\n",
    "    plt.figure(figsize=(3, 3), frameon=False)\n",
    "    im = val.reshape((28,28))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer of weights will be given as a single 16x16 matrix of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W2 = model.layers[3].get_weights()[0]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "im = W2.reshape((16,16))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(im, cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Further tweaks: weights and alternative optimizers\n",
    "Just to show off a few more tweaks, we'll run one final model. Here we use weights and an alternative to vanillia stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=(28 * 28,), init=\"glorot_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\",W_regularizer=l2(0.1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, init=\"glorot_normal\",W_regularizer=l2(0.1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=5,\n",
    "          verbose=1, show_accuracy=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
